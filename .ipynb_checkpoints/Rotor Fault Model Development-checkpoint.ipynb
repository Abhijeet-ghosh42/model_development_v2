{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30368a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow run: 3ca55ecbcf484916ba288aeb803f7ffd\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Setup & MLflow ---\n",
    "import os, joblib, yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "from mlflow_base import MLflowBase  # your wrapper\n",
    "\n",
    "# Experiment / run naming\n",
    "EXPERIMENT_NAME = \"rotor_fault_monitoring/16/78\"\n",
    "RUN_NAME        = \"pca_ocsvm_sidebands_v1\"   # algorithm/approach name\n",
    "\n",
    "# End any existing active run (notebook safety)\n",
    "if mlflow.active_run() is not None:\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Start run\n",
    "mlbase = MLflowBase(EXPERIMENT_NAME)\n",
    "run = mlbase.start_run(run_name=RUN_NAME)\n",
    "print(\"MLflow run:\", mlflow.active_run().info.run_id)\n",
    "\n",
    "# IDs & dataset\n",
    "dataset_path = \"iot.harmonics_m78_may26.csv\"\n",
    "tenant_id    = \"16\"\n",
    "machine_id   = \"78\"\n",
    "\n",
    "# Core training parameters\n",
    "n_components = 5\n",
    "svm_nu       = 0.05\n",
    "svm_gamma    = \"scale\"\n",
    "\n",
    "mlbase.log_params({\n",
    "    \"algorithm_name\": RUN_NAME,\n",
    "    \"dataset_path\": os.path.basename(dataset_path),\n",
    "    \"tenant_id\": tenant_id,\n",
    "    \"machine_id\": machine_id,\n",
    "    \"pca_n_components\": n_components,\n",
    "    \"svm_nu\": svm_nu,\n",
    "    \"svm_gamma\": svm_gamma,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5573f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (219396, 181)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>vh2_5</th>\n",
       "      <th>vh2_4</th>\n",
       "      <th>vh1_20</th>\n",
       "      <th>vh2_23</th>\n",
       "      <th>vh2_9</th>\n",
       "      <th>vh1_14</th>\n",
       "      <th>vh1_26</th>\n",
       "      <th>vh1_12</th>\n",
       "      <th>vh1_0</th>\n",
       "      <th>...</th>\n",
       "      <th>ch1_7</th>\n",
       "      <th>ch2_6</th>\n",
       "      <th>ch1_1</th>\n",
       "      <th>ch3_0</th>\n",
       "      <th>ch3_26</th>\n",
       "      <th>ch1_2</th>\n",
       "      <th>ch2_15</th>\n",
       "      <th>ch1_23</th>\n",
       "      <th>ch2_5</th>\n",
       "      <th>ch2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 00:00:04+00:00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.500000e+00</td>\n",
       "      <td>4.173536e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.594937e-23</td>\n",
       "      <td>-1.594937e-23</td>\n",
       "      <td>4.173536e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-01 00:00:26+00:00</td>\n",
       "      <td>5.59375</td>\n",
       "      <td>1.836682e-41</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.346868e-41</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-01 00:00:49+00:00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp    vh2_5         vh2_4        vh1_20  vh2_23  \\\n",
       "0 2024-03-01 00:00:04+00:00  0.00000  5.500000e+00  4.173536e-08     0.0   \n",
       "1 2024-03-01 00:00:26+00:00  5.59375  1.836682e-41  0.000000e+00     0.0   \n",
       "2 2024-03-01 00:00:49+00:00  0.00000  0.000000e+00  0.000000e+00     0.0   \n",
       "\n",
       "          vh2_9        vh1_14        vh1_26        vh1_12  vh1_0  ...  ch1_7  \\\n",
       "0  0.000000e+00 -1.594937e-23 -1.594937e-23  4.173536e-08    0.0  ...    NaN   \n",
       "1  7.346868e-41  0.000000e+00  0.000000e+00  0.000000e+00    0.0  ...    NaN   \n",
       "2  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00    0.0  ...    NaN   \n",
       "\n",
       "   ch2_6  ch1_1  ch3_0  ch3_26  ch1_2  ch2_15  ch1_23  ch2_5  ch2_3  \n",
       "0    NaN    NaN    NaN     NaN    NaN     NaN     NaN    NaN    NaN  \n",
       "1    NaN    NaN    NaN     NaN    NaN     NaN     NaN    NaN    NaN  \n",
       "2    NaN    NaN    NaN     NaN    NaN     NaN     NaN    NaN    NaN  \n",
       "\n",
       "[3 rows x 181 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell 2: Load & preprocess data ---\n",
    "df = pd.read_csv(dataset_path)\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "# Drop irrelevant columns if present\n",
    "drop_cols = [c for c in [\"_id\", \"tenant_id\", \"machine_id\", \"type\"] if c in df.columns]\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "print(\"Data shape:\", df.shape)\n",
    "display(df.head(3))\n",
    "\n",
    "harmonics_data = df.drop(columns=[\"timestamp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2390c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 3: Define AdvancedRotorFaultTrainer ---\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "\n",
    "class AdvancedRotorFaultTrainer:\n",
    "    def __init__(self, n_components, svm_nu, svm_gamma):\n",
    "        self.pca = PCA(n_components=n_components)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.svm = OneClassSVM(nu=svm_nu, gamma=svm_gamma)\n",
    "        self.imputer = SimpleImputer(strategy='mean')\n",
    "    \n",
    "#     def extract_sideband_features(self, harmonics_data, slip_freq=5, fundamental=50):\n",
    "#         harmonics_indices = [i for i in range(1, 31)]\n",
    "#         sideband_features = []\n",
    "\n",
    "#         for phase in ['ch', 'vh']:\n",
    "#             for h in harmonics_indices:\n",
    "#                 for ph in range(1, 3+1):\n",
    "#                     col = f\"{phase}{ph}_{h}\"\n",
    "#                     if col in harmonics_data.columns:\n",
    "#                         sideband_features.append(harmonics_data[col])\n",
    "#                     else:\n",
    "#                         sideband_features.append(np.nan)\n",
    "#         return np.array(sideband_features).T\n",
    "\n",
    "    def extract_sideband_features(self, harmonics_data, slip_freq=5, fundamental=50):\n",
    "        harmonics_indices = [i for i in range(1, 31)]\n",
    "        feature_cols = []\n",
    "\n",
    "        for phase in ['ch', 'vh']:\n",
    "            for h in harmonics_indices:\n",
    "                for ph in range(1, 4):   # 1‚Äì3 phases\n",
    "                    col = f\"{phase}{ph}_{h}\"\n",
    "                    if col in harmonics_data.columns:\n",
    "                        feature_cols.append(harmonics_data[col].values)\n",
    "                    else:\n",
    "                        print(f\"Warning: Column {col} missing, filling with NaN\")\n",
    "                        feature_cols.append(np.full(len(harmonics_data), np.nan))\n",
    "\n",
    "        # Stack into samples √ó features matrix\n",
    "        return np.column_stack(feature_cols)\n",
    "\n",
    "\n",
    "#     def fit(self, harmonics_data):\n",
    "#         sideband_data = self.extract_sideband_features(harmonics_data)\n",
    "#         imputed_data  = self.imputer.fit_transform(sideband_data)\n",
    "#         scaled_data   = self.scaler.fit_transform(imputed_data)\n",
    "#         pca_data      = self.pca.fit_transform(scaled_data)\n",
    "#         self.svm.fit(pca_data)\n",
    "#         return pca_data\n",
    "\n",
    "    def fit(self, harmonics_data):\n",
    "        t0 = time.time()\n",
    "        sideband_data = self.extract_sideband_features(harmonics_data)\n",
    "        print(f\"Feature extraction done in {time.time()-t0:.2f}s\")\n",
    "\n",
    "        t1 = time.time()\n",
    "        imputed_data  = self.imputer.fit_transform(sideband_data)\n",
    "        print(f\"Imputation done in {time.time()-t1:.2f}s\")\n",
    "\n",
    "        t2 = time.time()\n",
    "        scaled_data   = self.scaler.fit_transform(imputed_data)\n",
    "        print(f\"Scaling done in {time.time()-t2:.2f}s\")\n",
    "\n",
    "        t3 = time.time()\n",
    "        pca_data      = self.pca.fit_transform(scaled_data)\n",
    "        print(f\"PCA done in {time.time()-t3:.2f}s\")\n",
    "\n",
    "        t4 = time.time()\n",
    "        self.svm.fit(pca_data)\n",
    "        print(f\"SVM fit done in {time.time()-t4:.2f}s\")\n",
    "\n",
    "        print(f\"‚úÖ Total training time: {time.time()-t0:.2f}s\")\n",
    "        return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ea9d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column ch1_30 missing, filling with NaN\n",
      "Warning: Column ch2_30 missing, filling with NaN\n",
      "Warning: Column ch3_30 missing, filling with NaN\n",
      "Warning: Column vh1_30 missing, filling with NaN\n",
      "Warning: Column vh2_30 missing, filling with NaN\n",
      "Warning: Column vh3_30 missing, filling with NaN\n",
      "Feature extraction done in 0.02s\n",
      "Imputation done in 0.08s\n",
      "Scaling done in 0.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghosh\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: [ 87  88  89 177 178 179]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA done in 0.07s\n",
      "SVM fit done in 0.41s\n",
      "‚úÖ Total training time: 0.63s\n",
      "‚úÖ Model trained. PCA variance explained: 0.48903782820937\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: Train model ---\n",
    "trainer = AdvancedRotorFaultTrainer(n_components, svm_nu, svm_gamma)\n",
    "\n",
    "# just adding below code line to create a subset and quickly finish training so I can validate the pipeline, do not use this\n",
    "# when training\n",
    "harmonics_subset = harmonics_data.sample(n=5000, random_state=42)\n",
    "\n",
    "# pca_data = trainer.fit(harmonics_data)\n",
    "pca_data = trainer.fit(harmonics_subset)\n",
    "\n",
    "print(\"‚úÖ Model trained. PCA variance explained:\", trainer.pca.explained_variance_ratio_.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e36ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 11:38:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/18 11:38:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "INFO:botocore.credentials:Found credentials in environment variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model + Config logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 5: Log metrics & save model ---\n",
    "# Simple decision scores\n",
    "scores = trainer.svm.decision_function(pca_data)\n",
    "\n",
    "metrics = {\n",
    "    \"explained_variance\": float(trainer.pca.explained_variance_ratio_.sum()),\n",
    "    \"score_mean\": float(np.mean(scores)),\n",
    "    \"score_std\": float(np.std(scores)),\n",
    "}\n",
    "mlbase.log_metrics(metrics)\n",
    "\n",
    "# Save model locally\n",
    "model_path = f\"rotor_fault_detector_{machine_id}.pkl\"\n",
    "joblib.dump((trainer.imputer, trainer.scaler, trainer.pca, trainer.svm), model_path)\n",
    "\n",
    "# Log model in MLflow\n",
    "mlflow.sklearn.log_model(trainer.svm, artifact_path=\"model\")\n",
    "mlbase.log_artifact(run.info.run_id, local_path=model_path, artifact_path=\"artifacts\")\n",
    "\n",
    "# Save config YAML\n",
    "config = {\n",
    "    \"tenant_id\": tenant_id,\n",
    "    \"machine_id\": machine_id,\n",
    "    \"pca_n_components\": n_components,\n",
    "    \"svm_nu\": svm_nu,\n",
    "    \"svm_gamma\": svm_gamma,\n",
    "    \"decision_threshold\": float(np.percentile(scores, 5)),  # anomaly threshold\n",
    "    \"model_path\": model_path,\n",
    "}\n",
    "yaml_path = f\"rotor_fault_config_{machine_id}.yaml\"\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump(config, f, sort_keys=False)\n",
    "\n",
    "mlbase.log_artifact(run.info.run_id, local_path=yaml_path, artifact_path=\"configs\")\n",
    "print(\"‚úÖ Model + Config logged to MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40ae616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 5b: Attach run documentation (note) ---\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "def _fmt(x, nd=4):\n",
    "    if x is None or (isinstance(x, float) and (np.isnan(x) or np.isinf(x))):\n",
    "        return \"NaN\"\n",
    "    try:\n",
    "        return f\"{float(x):.{nd}f}\"\n",
    "    except Exception:\n",
    "        return str(x)\n",
    "\n",
    "mlflow.set_tag(\n",
    "    \"mlflow.note.content\",\n",
    "f\"\"\"\n",
    "# üåÄ Rotor Fault Detection ‚Äî Run Summary\n",
    "\n",
    "### Parameters\n",
    "- **Algorithm**: `{RUN_NAME}`\n",
    "- **Tenant / Machine**: `{tenant_id}` / `{machine_id}`\n",
    "- **Dataset**: `{os.path.basename(dataset_path)}`\n",
    "- **PCA components**: `{n_components}`\n",
    "- **SVM parameters**: ŒΩ = `{svm_nu}`, Œ≥ = `{svm_gamma}`\n",
    "\n",
    "### Key Metrics\n",
    "- **Explained variance (PCA)**: `{_fmt(metrics['explained_variance'])}`\n",
    "- **SVM score mean**: `{_fmt(metrics['score_mean'])}`\n",
    "- **SVM score std**: `{_fmt(metrics['score_std'])}`\n",
    "\n",
    "### Artifacts\n",
    "- **Model file**: `{model_path}`\n",
    "- **Config YAML**: `{yaml_path}`\n",
    "\n",
    "---\n",
    "\n",
    "**Usage**:  \n",
    "This run trained a PCA + OneClassSVM rotor fault model and logged it to MLflow.  \n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58eb8b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run pca_ocsvm_sidebands_v1 at: https://mlops.zolnoi.app/#/experiments/15/runs/3ca55ecbcf484916ba288aeb803f7ffd\n",
      "üß™ View experiment at: https://mlops.zolnoi.app/#/experiments/15\n",
      "MLflow run ended.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6: End MLflow run ---\n",
    "mlflow.end_run()\n",
    "print(\"MLflow run ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee103a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe8361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
