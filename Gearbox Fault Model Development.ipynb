{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a7c1113",
   "metadata": {},
   "source": [
    "# Gearbox Fault Model Training\n",
    "\n",
    "## What this notebook does\n",
    "We generate a **gearbox-fault configuration YAML** from harmonics data and **log everything to MLflow**.  \n",
    "This builds harmonic **profiles** (low/intermediate/high orders, optionally odd/even parity), computes per-profile stats for **normalization**, derives an **unlabeled fault score** with a baseline threshold, evaluates **Core-6** metrics, computes a **quality index**, and saves the **YAML artifact** our **real-time inferencing** service consumes.\n",
    "\n",
    "---\n",
    "\n",
    "## How to use (5 steps)\n",
    "1. **Fill the ‚ÄúEnter these configuration when onboarding new machines‚Äù block**\n",
    "   - `EXPERIMENT_NAME`, `RUN_NAME`, `dataset_path`, `tenant_id`, `machine_id`\n",
    "   - Tune **Algorithm/config knobs** and **Unlabeled evaluation settings** only if needed.\n",
    "2. **Run all cells top-to-bottom.**\n",
    "3. **Confirm outputs in the cell logs**\n",
    "   - Loaded shape, warnings (e.g., low valid rows), printed YAML, metrics, and MLflow run ID.\n",
    "4. **Verify in MLflow**\n",
    "   - Parameters, metrics (Core-6 + `quality_index`), artifact `gearbox_fault_configs_<machine_id>.yaml`, and run **Notes** tag.\n",
    "5. *(Optional)* Use the metrics to **select/promote** the best run in our registry/UI.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs & assumptions\n",
    "- CSV with harmonics columns named like:  \n",
    "  - `ch1_7` / `vh3_12` ‚Üí `c` or `v`, **phase** ‚àà {1,2,3}, **harmonic order** as integer.  \n",
    "- Optional `timestamp` column (parsed if present).  \n",
    "- Any `_id`, `metaData.tenant_id`, `metaData.machine_id` columns are dropped if present.\n",
    "\n",
    "---\n",
    "\n",
    "## What it computes (high level)\n",
    "- **Profiles** over harmonic buckets (RMS across chosen harmonics, then averaged across phases):\n",
    "  - Current: **low (1‚Äì10)**, **intermediate (11‚Äì20)**, **high (21‚Äì30)**  \n",
    "  - *(Optional)* **odd**/**even** parity profiles if `use_parity_profiles=True`\n",
    "- **Config YAML** with:\n",
    "  - `stoppage_current_threshold`\n",
    "  - `norm_args`: mean & std per profile (used for online normalization)\n",
    "- **Unlabeled evaluation**:\n",
    "  - Split by `BASELINE_FRACTION` (first part = presumed healthy **baseline**, remainder = **recent**)\n",
    "  - Z-normalize profiles on the baseline, combine into a **fault_score** (`AGGREGATION`: `max_z` or `mean_z`)\n",
    "  - Decision **threshold** from baseline (`THRESHOLD_METHOD`: `mean+3sigma` or `p99`)\n",
    "- **Core-6 metrics** (for comparability without labels):\n",
    "  - `drift_cohens_d`, `psi_fault_score`, `far_healthy`, `arl0_samples`, `recent_pct_time_anomalous`, `mean_profile_cv_baseline`\n",
    "- **quality_index** (single ranking score):  \n",
    "  `cohen_d ‚àí 5*far_healthy + 0.5*psi ‚àí 0.5*mean_profile_cv_baseline`\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs\n",
    "- **Artifact:** `gearbox_fault_configs_<machine_id>.yaml` (used by real-time detector)  \n",
    "- **MLflow logs:** parameters (IDs, knobs, eval settings), metrics (shape, Core-6, `quality_index`), artifact, and a **Run Documentation** note explaining each metric/knob.\n",
    "\n",
    "---\n",
    "\n",
    "## Parameters to change (when onboarding a new machine)\n",
    "\n",
    "| What | Variable(s) | Current | When to change |\n",
    "|---|---|---:|---|\n",
    "| **Experiment naming** | `EXPERIMENT_NAME`, `RUN_NAME` | `\"gearbox_fault_monitoring_testing/28/257\"`, `\"harmonic_profiling_kstest_v1\"` | Always set per tenant/machine or per approach/version. |\n",
    "| **Dataset path** | `dataset_path` | `\"iotts.harmonics_257.csv\"` | Point to the new machine‚Äôs harmonics CSV. |\n",
    "| **IDs** | `tenant_id`, `machine_id` | `\"28\"`, `\"257\"` | Always set for the new machine. |\n",
    "| **Stoppage filter** | `stoppage_current_threshold` | `40` | Adjust to our site‚Äôs ‚Äúmachine running‚Äù current; higher filters more idle periods. |\n",
    "| **Harmonic buckets** | `low_order_range`, `intermediate_order_range`, `high_order_range` | `(1,10)`, `(11,20)`, `(21,30)` | Change if our order definitions differ (e.g., extend to 40). |\n",
    "| **Parity profiles** | `use_parity_profiles` | `True` | Disable if odd/even split is not meaningful for that machine. |\n",
    "| **Baseline split** | `BASELINE_FRACTION` | `0.7` | Increase if we have a longer healthy history; decrease if drifted quickly. |\n",
    "| **Score aggregation** | `AGGREGATION` | `\"max_z\"` | `\"mean_z\"` is smoother; `\"max_z\"` is more sensitive to any profile spike. |\n",
    "| **Threshold rule** | `THRESHOLD_METHOD` | `\"mean+3sigma\"` | Use `\"p99\"` when baseline is skewed or heavy-tailed. |\n",
    "| **Column naming** | `extract_info` / `filter_harmonic_cols` | expects `ch<phase>_<order>`, `vh<phase>_<order>` | If our schema differs, update `extract_info` regex & mapping (`c`/`v`). |\n",
    "\n",
    "> **Keep the artifact naming pattern** (`gearbox_fault_configs_<machine_id>.yaml`) stable so serving can auto-discover it.\n",
    "\n",
    "---\n",
    "\n",
    "## How the YAML is used online\n",
    "- Serving loads the YAML, **normalizes** live profile values using `norm_args` (mean, std per profile), applies the **fault_score** rule and the stored **decision threshold** logic (same policy used here), and raises gearbox-fault flags when exceedance is persistent.\n",
    "\n",
    "---\n",
    "\n",
    "## Promotion guideline (rule of thumb)\n",
    "We promote when:\n",
    "- `far_healthy < 0.01` and `arl0_samples ‚â• 100`\n",
    "- `drift_cohens_d ‚â• 0.8`\n",
    "- `coverage_valid_row_fraction_min ‚â• 0.8`\n",
    "- `quality_index` ranks near the top across recent runs\n",
    "\n",
    "(Exact policy can be adapted per asset criticality and cost of false alarms.)\n",
    "\n",
    "---\n",
    "\n",
    "## Common gotchas\n",
    "- **Column parsing mismatch:** If our columns don‚Äôt match `ch<phase>_<order>` / `vh<phase>_<order>`, profiles become empty ‚Üí YAML stats become zeros. Fix `extract_info`.\n",
    "- **Sparse coverage:** Warnings like ‚Äúonly X valid rows‚Äù mean some profiles lack columns; check order ranges & naming.\n",
    "- **Mixed units/scales:** Ensure consistent preprocessing across data pulls or buckets; otherwise normalization drifts.\n",
    "- **Contaminated baseline:** If the first `BASELINE_FRACTION` includes faults, thresholds inflate; choose a clean baseline window or switch to `p99`.\n",
    "- **Idle periods:** Set `stoppage_current_threshold` so we don‚Äôt learn thresholds on non-operating data.\n",
    "\n",
    "---\n",
    "\n",
    "## TL;DR (quick start)\n",
    "- Update: `EXPERIMENT_NAME`, `RUN_NAME`, `dataset_path`, `tenant_id`, `machine_id`.  \n",
    "- (Optional) Tune: buckets, parity, baseline split, aggregation, threshold rule.  \n",
    "- Run all cells ‚Üí check printed YAML + MLflow run.  \n",
    "- Use `quality_index` and Core-6 to pick the best run.  \n",
    "- Deploy `gearbox_fault_configs_<machine_id>.yaml` to serving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a435ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Enter these configuration when onboarding new machines ---\n",
    "\n",
    "# Experiment / run naming\n",
    "EXPERIMENT_NAME = \"gearbox_fault_monitoring_testing/28/257\"\n",
    "RUN_NAME        = \"harmonic_profiling_kstest_v1\"   # algorithm/approach name\n",
    "\n",
    "# Data & IDs\n",
    "dataset_path = \"iotts.harmonics_257.csv\" # or dataset id\n",
    "tenant_id    = \"28\"\n",
    "machine_id   = \"257\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0946a34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run harmonic_profiling_kstest_v1 at: https://mlops.zolnoi.app/#/experiments/16/runs/5980ef708f524f0cb5998994020dbebc\n",
      "üß™ View experiment at: https://mlops.zolnoi.app/#/experiments/16\n",
      "MLflow run: 041bd7651d4c4afb9e4dd5713377eb4f\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Setting up MLflow ---\n",
    "import os, re, json, math, yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow_base import MLflowBase\n",
    "\n",
    "# End any existing active run (notebook safety)\n",
    "if mlflow.active_run() is not None:\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Start run\n",
    "mlbase = MLflowBase(EXPERIMENT_NAME)\n",
    "run = mlbase.start_run(run_name=RUN_NAME)\n",
    "print(\"MLflow run:\", mlflow.active_run().info.run_id)\n",
    "\n",
    "\n",
    "# Algorithm/config knobs\n",
    "stoppage_current_threshold = 40\n",
    "low_order_range, intermediate_order_range, high_order_range = (1,10), (11,20), (21,30)\n",
    "use_parity_profiles = True\n",
    "\n",
    "\n",
    "# Unlabeled evaluation settings\n",
    "BASELINE_FRACTION = 0.7                  # healthy portion\n",
    "AGGREGATION       = \"max_z\"              # \"max_z\" or \"mean_z\"\n",
    "THRESHOLD_METHOD  = \"mean+3sigma\"        # or \"p99\"\n",
    "\n",
    "\n",
    "# Logging important params\n",
    "mlbase.log_params({\n",
    "    \"algorithm_name\": RUN_NAME,\n",
    "    \"dataset_path\": os.path.basename(dataset_path),\n",
    "    \"tenant_id\": tenant_id,\n",
    "    \"machine_id\": machine_id,\n",
    "    \"stoppage_current_threshold\": stoppage_current_threshold,\n",
    "    \"low_order_range\": str(low_order_range),\n",
    "    \"intermediate_order_range\": str(intermediate_order_range),\n",
    "    \"high_order_range\": str(high_order_range),\n",
    "    \"use_parity_profiles\": use_parity_profiles,\n",
    "    \"eval_baseline_fraction\": BASELINE_FRACTION,\n",
    "    \"eval_aggregation\": AGGREGATION,\n",
    "    \"eval_threshold_method\": THRESHOLD_METHOD,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0d93da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (14491, 91)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>vh1_0</th>\n",
       "      <th>vh2_9</th>\n",
       "      <th>vh2_8</th>\n",
       "      <th>vh2_0</th>\n",
       "      <th>vh1_2</th>\n",
       "      <th>vh3_7</th>\n",
       "      <th>ch1_13</th>\n",
       "      <th>vh3_11</th>\n",
       "      <th>ch1_7</th>\n",
       "      <th>...</th>\n",
       "      <th>ch3_12</th>\n",
       "      <th>ch2_5</th>\n",
       "      <th>vh1_7</th>\n",
       "      <th>vh2_13</th>\n",
       "      <th>ch2_10</th>\n",
       "      <th>ch2_11</th>\n",
       "      <th>vh1_6</th>\n",
       "      <th>ch1_0</th>\n",
       "      <th>ch1_4</th>\n",
       "      <th>ch2_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-02 08:00:08+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686252</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.646852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.689831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-02 08:02:17+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605559</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.777842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-02 08:03:26+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579840</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.755995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.815620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  vh1_0  vh2_9     vh2_8  vh2_0     vh1_2  vh3_7  \\\n",
       "0 2025-08-02 08:00:08+00:00  100.0    0.0  0.686252  100.0  0.646852    0.0   \n",
       "1 2025-08-02 08:02:17+00:00  100.0    0.0  0.605559  100.0  0.777842    0.0   \n",
       "2 2025-08-02 08:03:26+00:00  100.0    0.0  0.579840  100.0  0.755995    0.0   \n",
       "\n",
       "   ch1_13  vh3_11  ch1_7  ...  ch3_12  ch2_5  vh1_7  vh2_13  ch2_10  ch2_11  \\\n",
       "0     0.0     0.0    0.0  ...     0.0    0.0    0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0    0.0  ...     0.0    0.0    0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0    0.0  ...     0.0    0.0    0.0     0.0     0.0     0.0   \n",
       "\n",
       "      vh1_6  ch1_0  ch1_4  ch2_8  \n",
       "0  1.689831    0.0    0.0    0.0  \n",
       "1  1.800501    0.0    0.0    0.0  \n",
       "2  1.815620    0.0    0.0    0.0  \n",
       "\n",
       "[3 rows x 91 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell 2: Load & basic health ---\n",
    "df = pd.read_csv(dataset_path)\n",
    "if \"timestamp\" in df.columns:\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "drop_cols = [c for c in [\"_id\",\"metaData.tenant_id\",\"metaData.machine_id\"] if c in df.columns]\n",
    "if drop_cols:\n",
    "    df = df.drop(columns=drop_cols)\n",
    "\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "display(df.head(3))\n",
    "\n",
    "missing_fraction_overall = float(df.isna().mean().mean()) if df.size else math.nan\n",
    "mlbase.log_metrics({\n",
    "    \"n_rows\": float(df.shape[0]),\n",
    "    \"n_cols\": float(df.shape[1]),\n",
    "    \"missing_fraction_overall\": missing_fraction_overall\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eec82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 3: Column parsing helpers ---\n",
    "def extract_info(col_name: str):\n",
    "    \"\"\"\n",
    "    Parse names like 'ch1_7' or 'vh3_12' => (type in {'c','v'}, phase in {1,2,3}, harmonic order int)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = col_name.split(\"_\")\n",
    "        type_phase_str = parts[0]\n",
    "        freq = int(parts[1])\n",
    "        m = re.match(r\"([a-z]+)([0-9]+)\", type_phase_str, re.I)\n",
    "        if not m: return (None, None, None)\n",
    "        type_str, phase_str = m.groups()\n",
    "        t = \"c\" if type_str.lower()==\"ch\" else \"v\" if type_str.lower()==\"vh\" else None\n",
    "        ph = int(phase_str)\n",
    "        return (t, ph, freq) if t in {\"c\",\"v\"} else (None, None, None)\n",
    "    except Exception:\n",
    "        return (None, None, None)\n",
    "\n",
    "def filter_harmonic_cols(df, t=\"c\", phase=None, order_range=None, parity=None):\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        tt, ph, fr = extract_info(col)\n",
    "        if tt != t or fr is None: continue\n",
    "        if phase is not None and ph != phase: continue\n",
    "        if order_range is not None:\n",
    "            lo, hi = order_range\n",
    "            if not (lo <= fr <= hi): continue\n",
    "        if parity == \"odd\"  and fr % 2 == 0: continue\n",
    "        if parity == \"even\" and fr % 2 != 0: continue\n",
    "        cols.append(col)\n",
    "    return cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edf7980d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghosh\\AppData\\Local\\Temp\\ipykernel_7520\\202380440.py:6: RuntimeWarning: Mean of empty slice\n",
      "  return pd.Series(np.sqrt(np.nanmean(np.square(vals), axis=1)), index=subdf.index)\n",
      "C:\\Users\\ghosh\\AppData\\Local\\Temp\\ipykernel_7520\\202380440.py:6: RuntimeWarning: Mean of empty slice\n",
      "  return pd.Series(np.sqrt(np.nanmean(np.square(vals), axis=1)), index=subdf.index)\n",
      "C:\\Users\\ghosh\\AppData\\Local\\Temp\\ipykernel_7520\\202380440.py:6: RuntimeWarning: Mean of empty slice\n",
      "  return pd.Series(np.sqrt(np.nanmean(np.square(vals), axis=1)), index=subdf.index)\n",
      "C:\\Users\\ghosh\\AppData\\Local\\Temp\\ipykernel_7520\\202380440.py:6: RuntimeWarning: Mean of empty slice\n",
      "  return pd.Series(np.sqrt(np.nanmean(np.square(vals), axis=1)), index=subdf.index)\n",
      "C:\\Users\\ghosh\\AppData\\Local\\Temp\\ipykernel_7520\\202380440.py:6: RuntimeWarning: Mean of empty slice\n",
      "  return pd.Series(np.sqrt(np.nanmean(np.square(vals), axis=1)), index=subdf.index)\n",
      "C:\\Users\\ghosh\\AppData\\Local\\Temp\\ipykernel_7520\\202380440.py:6: RuntimeWarning: Mean of empty slice\n",
      "  return pd.Series(np.sqrt(np.nanmean(np.square(vals), axis=1)), index=subdf.index)\n",
      "C:\\Users\\ghosh\\AppData\\Local\\Temp\\ipykernel_7520\\202380440.py:6: RuntimeWarning: Mean of empty slice\n",
      "  return pd.Series(np.sqrt(np.nanmean(np.square(vals), axis=1)), index=subdf.index)\n",
      "C:\\Users\\ghosh\\AppData\\Local\\Temp\\ipykernel_7520\\202380440.py:6: RuntimeWarning: Mean of empty slice\n",
      "  return pd.Series(np.sqrt(np.nanmean(np.square(vals), axis=1)), index=subdf.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: high_order_current_harmonics has only 0 valid rows.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4 (revised): Profiles & compact coverage logging ---\n",
    "def rms_across_harmonics(subdf: pd.DataFrame) -> pd.Series:\n",
    "    if subdf.empty: return pd.Series([], dtype=float)\n",
    "    vals = subdf.to_numpy(dtype=float)\n",
    "    with np.errstate(invalid=\"ignore\"):\n",
    "        return pd.Series(np.sqrt(np.nanmean(np.square(vals), axis=1)), index=subdf.index)\n",
    "\n",
    "def build_profile(df, t=\"c\", order_range=None, parity=None):\n",
    "    phase_series, debug = [], {}\n",
    "    for ph in [1,2,3]:\n",
    "        cols = filter_harmonic_cols(df, t=t, phase=ph, order_range=order_range, parity=parity)\n",
    "        debug[f\"phase{ph}_ncols\"] = len(cols)\n",
    "        phase_series.append(rms_across_harmonics(df[cols]) if cols else pd.Series(index=df.index, dtype=float))\n",
    "    stacked = pd.concat(phase_series, axis=1) if phase_series else pd.DataFrame(index=df.index)\n",
    "    profile = stacked.mean(axis=1, skipna=True) if not stacked.empty else pd.Series(index=df.index, dtype=float)\n",
    "    debug[\"rows\"] = int(df.shape[0])\n",
    "    debug[\"valid_rows\"] = int(profile.dropna().shape[0])\n",
    "    return profile, debug\n",
    "\n",
    "profiles_to_compute = {\n",
    "    \"low_order_current_harmonics\":          dict(t=\"c\", order_range=(1,10),  parity=None),\n",
    "    \"intermediate_order_current_harmonics\": dict(t=\"c\", order_range=(11,20), parity=None),\n",
    "    \"high_order_current_harmonics\":         dict(t=\"c\", order_range=(21,30), parity=None),\n",
    "}\n",
    "if use_parity_profiles:\n",
    "    profiles_to_compute.update({\n",
    "        \"odd_parity_current_harmonics\":  dict(t=\"c\", order_range=None, parity=\"odd\"),\n",
    "        \"even_parity_current_harmonics\": dict(t=\"c\", order_range=None, parity=\"even\"),\n",
    "    })\n",
    "\n",
    "profile_series_map, profile_debug_map = {}, {}\n",
    "profile_valid_fracs = []\n",
    "profiles_used = 0\n",
    "\n",
    "for pname, args in profiles_to_compute.items():\n",
    "    s, dbg = build_profile(df, **args)\n",
    "    profile_series_map[pname] = s\n",
    "    profile_debug_map[pname] = dbg\n",
    "\n",
    "    if dbg[\"rows\"] > 0:\n",
    "        valid_frac = dbg[\"valid_rows\"] / dbg[\"rows\"]\n",
    "        profile_valid_fracs.append(valid_frac)\n",
    "    if dbg[\"valid_rows\"] > 0:\n",
    "        profiles_used += 1\n",
    "\n",
    "# Aggregate coverage signals (compact)\n",
    "coverage_min = float(np.min(profile_valid_fracs)) if profile_valid_fracs else float(\"nan\")\n",
    "mlbase.log_metrics({\"coverage_valid_row_fraction_min\": coverage_min})\n",
    "mlbase.log_params({\"profiles_used\": int(profiles_used)})\n",
    "\n",
    "# Optional: warn if any profile has very low valid rows\n",
    "for pname, dbg in profile_debug_map.items():\n",
    "    if dbg[\"valid_rows\"] < 50:\n",
    "        print(f\"WARNING: {pname} has only {dbg['valid_rows']} valid rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f506df30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated Gearbox Fault Detection Config (YAML):\n",
      "stoppage_current_threshold: 40\n",
      "norm_args:\n",
      "  low_order_current_harmonics:\n",
      "  - 0.521031\n",
      "  - 0.783555\n",
      "  intermediate_order_current_harmonics:\n",
      "  - 0.09268\n",
      "  - 0.153546\n",
      "  high_order_current_harmonics:\n",
      "  - 0.0\n",
      "  - 0.0\n",
      "  odd_parity_current_harmonics:\n",
      "  - 0.027823\n",
      "  - 0.043371\n",
      "  even_parity_current_harmonics:\n",
      "  - 12.519126\n",
      "  - 16.92035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 5: Build config & save YAML (artifact) ---\n",
    "def safe_pair(mean_val, std_val):\n",
    "    m = float(mean_val) if not np.isnan(mean_val) else 0.0\n",
    "    s = float(std_val)  if not np.isnan(std_val)  else 0.0\n",
    "    return [round(m,6), round(s,6)]\n",
    "\n",
    "# Compute mean/std per profile\n",
    "profile_stats_map = {\n",
    "    p: {\n",
    "        \"mean\": float(v.dropna().mean()) if v.dropna().size else float(\"nan\"),\n",
    "        \"std\":  float(v.dropna().std(ddof=0)) if v.dropna().size>1 else 0.0\n",
    "    }\n",
    "    for p, v in profile_series_map.items()\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"stoppage_current_threshold\": stoppage_current_threshold,\n",
    "    \"norm_args\": {\n",
    "        \"low_order_current_harmonics\":          safe_pair(profile_stats_map[\"low_order_current_harmonics\"][\"mean\"],          profile_stats_map[\"low_order_current_harmonics\"][\"std\"]),\n",
    "        \"intermediate_order_current_harmonics\": safe_pair(profile_stats_map[\"intermediate_order_current_harmonics\"][\"mean\"], profile_stats_map[\"intermediate_order_current_harmonics\"][\"std\"]),\n",
    "        \"high_order_current_harmonics\":         safe_pair(profile_stats_map[\"high_order_current_harmonics\"][\"mean\"],         profile_stats_map[\"high_order_current_harmonics\"][\"std\"]),\n",
    "    }\n",
    "}\n",
    "if use_parity_profiles:\n",
    "    config[\"norm_args\"][\"odd_parity_current_harmonics\"]  = safe_pair(profile_stats_map[\"odd_parity_current_harmonics\"][\"mean\"],  profile_stats_map[\"odd_parity_current_harmonics\"][\"std\"])\n",
    "    config[\"norm_args\"][\"even_parity_current_harmonics\"] = safe_pair(profile_stats_map[\"even_parity_current_harmonics\"][\"mean\"], profile_stats_map[\"even_parity_current_harmonics\"][\"std\"])\n",
    "\n",
    "output_yaml = f\"gearbox_fault_configs_{machine_id}.yaml\"\n",
    "with open(output_yaml, \"w\") as f:\n",
    "    yaml.dump(config, f, sort_keys=False, default_flow_style=False)\n",
    "\n",
    "print(\"‚úÖ Generated Gearbox Fault Detection Config (YAML):\")\n",
    "print(yaml.dump(config, sort_keys=False, default_flow_style=False))\n",
    "\n",
    "# Log the YAML artifact (the deliverable)\n",
    "mlbase.log_artifact(run.info.run_id, local_path=output_yaml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "480ce4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged metrics: {'drift_cohens_d': 0.3574004000931431, 'psi_fault_score': 0.14174696734949796, 'far_healthy': 0.006802721088435374, 'arl0_samples': 147.0, 'recent_pct_time_anomalous': 0.005059797608095676, 'mean_profile_cv_baseline': 1.74054039145304}\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6 - A (revised): Unlabeled evaluation ‚Äî Core-6 metrics only ---\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# 1) Composite fault score from profiles (z-normalized on baseline)\n",
    "profiles_df = pd.DataFrame(profile_series_map).sort_index()\n",
    "n = len(profiles_df)\n",
    "split_idx = int(n * BASELINE_FRACTION)\n",
    "\n",
    "baseline_df = profiles_df.iloc[:split_idx].copy()\n",
    "recent_df   = profiles_df.iloc[split_idx:].copy()\n",
    "\n",
    "baseline_means = baseline_df.mean(skipna=True)\n",
    "baseline_stds  = baseline_df.std(skipna=True).replace(0, np.nan)\n",
    "\n",
    "z_df     = (profiles_df - baseline_means) / baseline_stds\n",
    "z_pos_df = z_df.clip(lower=0)\n",
    "\n",
    "if AGGREGATION == \"mean_z\":\n",
    "    fault_score = z_pos_df.mean(axis=1, skipna=True)\n",
    "else:  # default \"max_z\"\n",
    "    fault_score = z_pos_df.max(axis=1, skipna=True)\n",
    "\n",
    "baseline_scores = fault_score.iloc[:split_idx].dropna()\n",
    "recent_scores   = fault_score.iloc[split_idx:].dropna()\n",
    "\n",
    "# 2) Threshold from baseline\n",
    "if THRESHOLD_METHOD == \"p99\":\n",
    "    thr = float(np.nanpercentile(baseline_scores, 99))\n",
    "else:  # \"mean+3sigma\"\n",
    "    thr = float(baseline_scores.mean() + 3 * baseline_scores.std())\n",
    "\n",
    "mlbase.log_params({\"eval_decision_threshold\": thr})\n",
    "\n",
    "# 3) Helper funcs\n",
    "def cohens_d(a, b):\n",
    "    a, b = np.asarray(a, float), np.asarray(b, float)\n",
    "    a, b = a[~np.isnan(a)], b[~np.isnan(b)]\n",
    "    if a.size < 2 or b.size < 2: return float(\"nan\")\n",
    "    m1, m2 = a.mean(), b.mean()\n",
    "    s = np.sqrt(((a.var(ddof=1) + b.var(ddof=1)) / 2.0))\n",
    "    return float((m2 - m1) / s) if s > 0 else float(\"nan\")\n",
    "\n",
    "def psi(a, b, bins=10):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    a = a[~np.isnan(a)]; b = b[~np.isnan(b)]\n",
    "    if a.size < 10 or b.size < 10: return float(\"nan\")\n",
    "    qs = np.quantile(a, np.linspace(0,1,bins+1)); qs[0], qs[-1] = -np.inf, np.inf\n",
    "    val = 0.0\n",
    "    for i in range(bins):\n",
    "        p = ((a>=qs[i]) & (a<qs[i+1])).mean()\n",
    "        q = ((b>=qs[i]) & (b<qs[i+1])).mean()\n",
    "        p = max(p,1e-6); q = max(q,1e-6)\n",
    "        val += (q-p) * np.log(q/p)\n",
    "    return float(val)\n",
    "\n",
    "# 4) Core-6 metrics\n",
    "cohen_d = cohens_d(baseline_scores, recent_scores)          # separability\n",
    "psi_val = psi(baseline_scores, recent_scores, bins=10)      # distribution shift\n",
    "far_healthy = float(np.mean(baseline_scores >= thr))        # false alarms on baseline\n",
    "arl0 = float(1.0 / max(far_healthy, 1e-9))                  # expected samples between false alarms\n",
    "recent_flags = (recent_scores >= thr).astype(int)\n",
    "pct_time_anom_recent = float(recent_flags.mean())           # % anomalous in recent\n",
    "# mean CV across profiles on baseline\n",
    "cv_vals = []\n",
    "for p in baseline_df.columns:\n",
    "    mu = baseline_df[p].mean(skipna=True)\n",
    "    sd = baseline_df[p].std(skipna=True)\n",
    "    cv = (sd/mu) if (mu not in [0, np.nan] and not np.isnan(mu)) else np.nan\n",
    "    if not np.isnan(cv): cv_vals.append(cv)\n",
    "mean_profile_cv_baseline = float(np.mean(cv_vals)) if cv_vals else float(\"nan\")\n",
    "\n",
    "# Log ONLY the Core-6\n",
    "mlbase.log_metrics({\n",
    "    \"drift_cohens_d\": cohen_d,\n",
    "    \"psi_fault_score\": psi_val,\n",
    "    \"far_healthy\": far_healthy,\n",
    "    \"arl0_samples\": arl0,\n",
    "    \"recent_pct_time_anomalous\": pct_time_anom_recent,\n",
    "    \"mean_profile_cv_baseline\": mean_profile_cv_baseline\n",
    "})\n",
    "\n",
    "print(\"Logged metrics:\",\n",
    "      {k: v for k, v in {\n",
    "          \"drift_cohens_d\": cohen_d,\n",
    "          \"psi_fault_score\": psi_val,\n",
    "          \"far_healthy\": far_healthy,\n",
    "          \"arl0_samples\": arl0,\n",
    "          \"recent_pct_time_anomalous\": pct_time_anom_recent,\n",
    "          \"mean_profile_cv_baseline\": mean_profile_cv_baseline\n",
    "      }.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e00c1d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality_index: -0.4760099174008047\n"
     ]
    }
   ],
   "source": [
    "# Cell 6-B : A single quality index to sort runs \n",
    "quality_index = (\n",
    "    (cohen_d)\n",
    "    - 5.0 * (far_healthy)\n",
    "    + 0.5 * (psi_val if not np.isnan(psi_val) else 0.0)\n",
    "    - 0.5 * (mean_profile_cv_baseline if not np.isnan(mean_profile_cv_baseline) else 0.0)\n",
    ")\n",
    "mlbase.log_metrics({\"quality_index\": float(quality_index)})\n",
    "print(\"quality_index:\", quality_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fd17080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell X: Run documentation (Notes) ---\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "def _fmt(x, nd=4):\n",
    "    if x is None or (isinstance(x, float) and (np.isnan(x) or np.isinf(x))):\n",
    "        return \"NaN\"\n",
    "    try:\n",
    "        return f\"{float(x):.{nd}f}\"\n",
    "    except Exception:\n",
    "        return str(x)\n",
    "\n",
    "mlflow.set_tag(\n",
    "    \"mlflow.note.content\",\n",
    "f\"\"\"\n",
    "### Run Documentation\n",
    "\n",
    "This note summarizes **what we logged** in MLflow for quick comparison across runs and why each item matters.\n",
    "\n",
    "---\n",
    "\n",
    "#### üì¶ Artifact (the deliverable)\n",
    "- **Config YAML**: `{output_yaml}`    \n",
    "  This is the file used by the online realtime detector.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚öôÔ∏è Parameters (setup & reproducibility)\n",
    "- **algorithm_name**: `{RUN_NAME}` ‚Äî approach used to generate the config.\n",
    "- **tenant_id / machine_id**: `{tenant_id}` / `{machine_id}` ‚Äî routing & traceability.\n",
    "- **dataset_path**: `{os.path.basename(dataset_path)}` ‚Äî source data identifier.\n",
    "- **stoppage_current_threshold**: `{stoppage_current_threshold}` ‚Äî filters non-operating periods.\n",
    "- **harmonic buckets**: low `{low_order_range}`, intermediate `{intermediate_order_range}`, high `{high_order_range}`.\n",
    "- **use_parity_profiles**: `{use_parity_profiles}` ‚Äî include odd/even profiles.\n",
    "- **eval_baseline_fraction**: `{BASELINE_FRACTION}` ‚Äî portion assumed healthy to derive baseline.\n",
    "- **eval_aggregation**: `{AGGREGATION}` ‚Äî how profiles combine into one fault score.\n",
    "- **eval_threshold_method**: `{THRESHOLD_METHOD}` ‚Äî rule for decision threshold on baseline.\n",
    "- **profiles_used**: `{profiles_used}` ‚Äî number of profiles with usable data.\n",
    "- **eval_decision_threshold**: `{_fmt(thr)}` ‚Äî derived operating threshold for the fault score.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìä Core Metrics (for benchmarking without labels)\n",
    "- **missing_fraction_overall**: `{_fmt(missing_fraction_overall)}` ‚Äî overall data completeness.\n",
    "- **coverage_valid_row_fraction_min**: `{_fmt(coverage_min)}` ‚Äî worst coverage across profiles.\n",
    "\n",
    "**Separability & shift**\n",
    "- **drift_cohens_d**: `{_fmt(cohen_d)}` ‚Äî effect size between recent vs baseline fault scores.\n",
    "- **psi_fault_score**: `{_fmt(psi_val)}` ‚Äî population stability index for fault score.\n",
    "\n",
    "**False-alarm behavior**\n",
    "- **far_healthy**: `{_fmt(far_healthy)}` ‚Äî fraction of baseline flagged.\n",
    "- **arl0_samples**: `{_fmt(arl0)}` ‚Äî expected samples between false alarms.\n",
    "\n",
    "**Operational recent behavior**\n",
    "- **recent_pct_time_anomalous**: `{_fmt(pct_time_anom_recent)}` ‚Äî fraction of recent period flagged.\n",
    "\n",
    "**Baseline stability**\n",
    "- **mean_profile_cv_baseline**: `{_fmt(mean_profile_cv_baseline)}` ‚Äî average coefficient of variation across profiles in healthy window.\n",
    "\n",
    "**Single ranking score**\n",
    "- **quality_index**: `{_fmt(quality_index)}`  \n",
    "  Formula: `cohen_d - 5*far_healthy + 0.5*psi - 0.5*mean_profile_cv_baseline`.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Promotion guideline\n",
    "Promote when:\n",
    "- `far_healthy < 0.01` and `arl0_samples ‚â• 100`, **and**\n",
    "- `drift_cohens_d ‚â• 0.8`, **and**\n",
    "- `coverage_valid_row_fraction_min ‚â• 0.8`, **and**\n",
    "- `quality_index` ranks near the top among runs for this machine/config family.\n",
    "\n",
    "*Aggregation:* `{AGGREGATION}` ¬∑ *Thresholding:* `{THRESHOLD_METHOD}` ¬∑ *Baseline fraction:* `{BASELINE_FRACTION}`\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "264aea5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low_order_current_harmonics</th>\n",
       "      <th>intermediate_order_current_harmonics</th>\n",
       "      <th>high_order_current_harmonics</th>\n",
       "      <th>odd_parity_current_harmonics</th>\n",
       "      <th>even_parity_current_harmonics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14491.000000</td>\n",
       "      <td>14491.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14491.000000</td>\n",
       "      <td>14491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.521031</td>\n",
       "      <td>0.092680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027823</td>\n",
       "      <td>12.519126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.153551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043372</td>\n",
       "      <td>16.920934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.048286</td>\n",
       "      <td>0.158427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061778</td>\n",
       "      <td>35.374847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.307929</td>\n",
       "      <td>1.712915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.876519</td>\n",
       "      <td>36.245903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       low_order_current_harmonics  intermediate_order_current_harmonics  \\\n",
       "count                 14491.000000                          14491.000000   \n",
       "mean                      0.521031                              0.092680   \n",
       "std                       0.783582                              0.153551   \n",
       "min                       0.000000                              0.000000   \n",
       "25%                       0.000000                              0.000000   \n",
       "50%                       0.000000                              0.000000   \n",
       "75%                       1.048286                              0.158427   \n",
       "max                       6.307929                              1.712915   \n",
       "\n",
       "       high_order_current_harmonics  odd_parity_current_harmonics  \\\n",
       "count                           0.0                  14491.000000   \n",
       "mean                            NaN                      0.027823   \n",
       "std                             NaN                      0.043372   \n",
       "min                             NaN                      0.000000   \n",
       "25%                             NaN                      0.000000   \n",
       "50%                             NaN                      0.000000   \n",
       "75%                             NaN                      0.061778   \n",
       "max                             NaN                      0.876519   \n",
       "\n",
       "       even_parity_current_harmonics  \n",
       "count                   14491.000000  \n",
       "mean                       12.519126  \n",
       "std                        16.920934  \n",
       "min                         0.000000  \n",
       "25%                         0.000000  \n",
       "50%                         0.000000  \n",
       "75%                        35.374847  \n",
       "max                        36.245903  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold (baseline-derived): 3.74718309784166\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 7: Quick sanity view (optional) ---\n",
    "check_df = pd.DataFrame(profile_series_map)\n",
    "display(check_df.describe())\n",
    "print(\"Threshold (baseline-derived):\", thr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a82dd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run harmonic_profiling_kstest_v1 at: https://mlops.zolnoi.app/#/experiments/16/runs/041bd7651d4c4afb9e4dd5713377eb4f\n",
      "üß™ View experiment at: https://mlops.zolnoi.app/#/experiments/16\n",
      "MLflow run ended.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 8: End MLflow run ---\n",
    "mlflow.end_run()\n",
    "print(\"MLflow run ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8faee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
